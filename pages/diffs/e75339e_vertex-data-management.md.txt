diff --git a/docs/games/optimize/vertex-data-management.md b/docs/games/optimize/vertex-data-management.md
index 0c282d7..1bfa641 100644
--- a/docs/games/optimize/vertex-data-management.md
+++ b/docs/games/optimize/vertex-data-management.md
@@ -4,9 +4,7 @@ url: https://developer.android.com/games/optimize/vertex-data-management
 source: md.txt
 ---
 
-# Vertex data management
-
-Good vertex data layout and compression is integral to the performance of any graphical application, whether an app consists of 2D user interfaces or is a large 3D open world game. Internal testing with[Android GPU Inspector's](https://developer.android.com/agi)Frame Profiler on dozens of top Android Games indicates that much could be done to improve vertex data management. We have observed that it's common for vertex data to use full precision, 32-bit float values for all vertex attributes, and a vertex buffer layout that uses an array of structures formatted with fully interleaved attributes.
+Good vertex data layout and compression is integral to the performance of any graphical application, whether an app consists of 2D user interfaces or is a large 3D open world game. Internal testing with [Android GPU Inspector's](https://developer.android.com/agi) Frame Profiler on dozens of top Android Games indicates that much could be done to improve vertex data management. We have observed that it's common for vertex data to use full precision, 32-bit float values for all vertex attributes, and a vertex buffer layout that uses an array of structures formatted with fully interleaved attributes.
 
 This article discusses how to optimize the graphics performance of your Android application by using the following techniques:
 
@@ -19,11 +17,13 @@ All data presented comes from an example static scene containing \~19,000,000 ve
 
 ![Sample scene with 6 rings and 19m vertices](https://developer.android.com/static/images/games/vertex/vertex-example-static-scene.png)
 
-**Figure 1:**Sample scene with 6 rings and 19m vertices
+**Figure
+1:** Sample scene with 6 rings and 19m vertices
 
 ## Vertex compression
 
-Vertex Compression is an umbrella term for lossy compression techniques that use efficient packing to reduce the size of vertex data both during runtime and in storage. Reducing the size of vertices has several benefits, including reducing memory bandwidth on the GPU (by trading compute for bandwidth), improving cache utilization, and potentially reducing the risk of spilling registers.
+Vertex Compression is an umbrella term for lossy compression techniques that
+use efficient packing to reduce the size of vertex data both during runtime and in storage. Reducing the size of vertices has several benefits, including reducing memory bandwidth on the GPU (by trading compute for bandwidth), improving cache utilization, and potentially reducing the risk of spilling registers.
 
 Common approaches to Vertex Compression include:
 
@@ -34,7 +34,7 @@ For example, if a vertex uses full 32-bit floats for position (vec3), normal (ve
 
 ### Vertex positions
 
-Vertex position data can be compressed from full precision 32-bit floating point values to half precision 16-bit floating point values in the vast majority of meshes, and half floats are supported in hardware on almost all mobile devices. A conversion function going from float32 to float16 looks like this ([adapted from this guide](https://apprize.best/programming/opengl/19.html)):  
+Vertex position data can be compressed from full precision 32-bit floating point values to half precision 16-bit floating point values in the vast majority of meshes, and half floats are supported in hardware on almost all mobile devices. A conversion function going from float32 to float16 looks like this ([adapted from this guide](https://apprize.best/programming/opengl/19.html)):
 
     uint16_t f32_to_f16(float f) {
       uint32_t x = (uint32_t)f;
@@ -68,14 +68,14 @@ Vertex position data can be compressed from full precision 32-bit floating point
       return hf;
     }
 
-There is a limitation to this approach; precision degrades as the vertex gets farther from the origin, making it less suitable for meshes that are very large spatially (vertices that have elements that go beyond 1024). You can address this by splitting up a mesh into smaller chunks, centering each chunk around the model origin, and scaling so that all the vertices for each chunk fit within the \[-1, 1\] range, which contains the highest precision for floating point values. The pseudocode for compression looks like this:  
+There is a limitation to this approach; precision degrades as the vertex gets farther from the origin, making it less suitable for meshes that are very large spatially (vertices that have elements that go beyond 1024). You can address this by splitting up a mesh into smaller chunks, centering each chunk around the model origin, and scaling so that all the vertices for each chunk fit within the \[-1, 1\] range, which contains the highest precision for floating point values. The pseudocode for compression looks like this:
 
     for each position p in Mesh:
        p -= center_of_bounding_box // Moves Mesh back to the center of model space
        p /= half_size_bounding_box // Fits the mesh into a [-1, 1] cube
        vec3<float16> result = vec3(f32_to_f16(p.x), f32_to_f16(p.y), f32_to_f16(p.z));
 
-You bake the scale factor and translation into the model matrix in order to decompress the vertex data when rendering. Keep in mind that you don't want to use this same model matrix for transforming normals, as they didn't have the same compression applied. You will need a matrix without these decompression transformations for normals, or you can use the base model matrix (which you can use for normals) and then apply the additional decompression transformations to the model matrix within the shader. An example:  
+You bake the scale factor and translation into the model matrix in order to decompress the vertex data when rendering. Keep in mind that you don't want to use this same model matrix for transforming normals, as they didn't have the same compression applied. You will need a matrix without these decompression transformations for normals, or you can use the base model matrix (which you can use for normals) and then apply the additional decompression transformations to the model matrix within the shader. An example:
 
     vec3 in in_pos;
 
@@ -86,7 +86,7 @@ You bake the scale factor and translation into the model matrix in order to deco
        gl_Position = proj * view * model * decompress_pos;
     }
 
-Another approach involves using[Signed Normalized Integers (SNORM)](https://www.khronos.org/opengl/wiki/Normalized_Integer#Signed). SNORM data types use integers rather than floating point to represent values between \[-1, 1\]. Using a 16-bit SNORM for positions gives you the same memory savings as a float16 without the drawbacks of non-uniform distributions. An implementation we recommend for using SNORM looks like this:  
+Another approach involves using [Signed Normalized Integers (SNORM)](https://www.khronos.org/opengl/wiki/Normalized_Integer#Signed). SNORM data types use integers rather than floating point to represent values between \[-1, 1\]. Using a 16-bit SNORM for positions gives you the same memory savings as a float16 without the drawbacks of non-uniform distributions. An implementation we recommend for using SNORM looks like this:
 
     const int BITS = 16
 
@@ -96,10 +96,10 @@ Another approach involves using[Signed Normalized Integers (SNORM)](https://www.
        // float to integer value conversion
        p = clamp(p * (2^(BITS - 1) - 1), -2^(BITS - 1), 2^(BITS - 1) - 1) 
 
-|            |          Format           |   Size   |
-|------------|---------------------------|----------|
-| **Before** | vec4\<`float32`\>         | 16 bytes |
-| **After**  | vec3\<`float16/SNORM16`\> | 6 bytes  |
+|   | Format | Size |
+|---|---|---|
+| **Before** | vec4\<`float32`\> | 16 bytes |
+| **After** | vec3\<`float16/SNORM16`\> | 6 bytes |
 
 ### Vertex normals and tangent space
 
@@ -111,7 +111,7 @@ The tangent space is a coordinate system where every vertex consists of the norm
 
 These vectors can typically be represented using 16-bit floats without any perceptual loss in visual fidelity, so that's a good place to start!
 
-We can compress further with a[technique known as QTangents](https://dl.acm.org/doi/10.1145/2037826.2037841)that stores the entire tangent space in a single quaternion. Since quaternions can be used to represent rotations, by thinking of the tangent space vectors as column vectors of a 3x3 matrix representing a rotation (in this case from model space into the tangent space) we can convert between the two! A quaternion can be treated as vec4 data-wise, and a conversion from tangent space vectors to a QTangent based on the paper linked above and[adapted from the implementation here](https://www.yosoygames.com.ar/wp/2018/03/vertex-formats-part-1-compression/)is as follows:  
+We can compress further with a [technique known as QTangents](https://dl.acm.org/doi/10.1145/2037826.2037841) that stores the entire tangent space in a single quaternion. Since quaternions can be used to represent rotations, by thinking of the tangent space vectors as column vectors of a 3x3 matrix representing a rotation (in this case from model space into the tangent space) we can convert between the two! A quaternion can be treated as vec4 data-wise, and a conversion from tangent space vectors to a QTangent based on the paper linked above and [adapted from the implementation here](https://www.yosoygames.com.ar/wp/2018/03/vertex-formats-part-1-compression/) is as follows:
 
     const int BITS = 16
 
@@ -145,14 +145,14 @@ We can compress further with a[technique known as QTangents](https://dl.acm.org/
        return qTangent;
     }
 
-The quaternion will be normalized, and you will be able to compress it using SNORMs. 16-bit SNORMs give good precision and memory savings. 8-bit SNORMs can provide even more savings, but may cause artifacts on highly specular materials. You can try both and see what works best for your assets! Encoding the quaternion looks like this:  
+The quaternion will be normalized, and you will be able to compress it using SNORMs. 16-bit SNORMs give good precision and memory savings. 8-bit SNORMs can provide even more savings, but may cause artifacts on highly specular materials. You can try both and see what works best for your assets! Encoding the quaternion looks like this:
 
     for each vertex v in mesh:
        quaternion res = tangent_space_to_quat(v.normal, v.tangent, v.bitangent);
        // Once we have the quaternion we can compress it
        res = clamp(res * (2^(BITS - 1) - 1), -2^(BITS - 1), 2^(BITS - 1) - 1);
 
-To decode the quaternion in the vertex shader ([adapted from here](https://www.yosoygames.com.ar/wp/2018/03/vertex-formats-part-1-compression/)):  
+To decode the quaternion in the vertex shader ([adapted from here](https://www.yosoygames.com.ar/wp/2018/03/vertex-formats-part-1-compression/)):
 
     vec3 xAxis( vec4 qQuat )
     {
@@ -192,18 +192,19 @@ To decode the quaternion in the vertex shader ([adapted from here](https://www.y
       ...
     }
 
-|            |                          Format                           |   Size   |
-|------------|-----------------------------------------------------------|----------|
+|   | Format | Size |
+|---|---|---|
 | **Before** | vec3\<`float32`\> + vec3\<`float32`\> + vec3\<`float32`\> | 36 bytes |
-| **After**  | vec4\<`SNORM16`\>                                         | 8 bytes  |
+| **After** | vec4\<`SNORM16`\> | 8 bytes |
 
 #### Normals Only
 
-If you only need to store normal vectors, there is a different approach that can lead to more savings - using[Octahedral Mapping of unit vectors rather than Cartesian Coordinates to compress the normal vector](http://jcgt.org/published/0003/02/01/). Octahedral Mapping works by projecting a unit sphere to an octahedron, and then projecting the octahedron down to a 2D plane. The result is that you can represent any normal vector using just two numbers. These two numbers can be thought of as texture coordinates we use to "sample" the 2D plane we projected the sphere onto, allowing us to recover the original vector. These two numbers can then be stored in an SNORM8.
+If you only need to store normal vectors, there is a different approach that can lead to more savings - using [Octahedral Mapping of unit vectors rather than Cartesian Coordinates to compress the normal vector](http://jcgt.org/published/0003/02/01/). Octahedral Mapping works by projecting a unit sphere to an octahedron, and then projecting the octahedron down to a 2D plane. The result is that you can represent any normal vector using just two numbers. These two numbers can be thought of as texture coordinates we use to "sample" the 2D plane we projected the sphere onto, allowing us to recover the original vector. These two numbers can then be stored in an SNORM8.
 
 ![Projecting a unit sphere to an octahedron and projecting the octahedron to a 2D plane](https://developer.android.com/images/games/vertex/vertex-octahedral-mapping-visualized.svg "Octahedral Mapping Visualized")
 
-**Figure 2:** Octahedral Mapping Visualized ([source](http://jcgt.org/published/0003/02/01/))  
+**Figure
+2:** Octahedral Mapping Visualized ([source](http://jcgt.org/published/0003/02/01/))
 
     const int BITS = 8
 
@@ -221,7 +222,7 @@ If you only need to store normal vectors, there is a different approach that can
       }
       res = clamp(res * (2^(BITS - 1) - 1), -2^(BITS - 1), 2^(BITS - 1) - 1)
 
-Decompression in the vertex shader (to convert back to cartesian coordinates) is inexpensive; with most modern mobile devices we did not see any major performance degradation when implementing this technique. The decompression in the vertex shader:  
+Decompression in the vertex shader (to convert back to cartesian coordinates) is inexpensive; with most modern mobile devices we did not see any major performance degradation when implementing this technique. The decompression in the vertex shader:
 
     //Additional Optimization: twitter.com/Stubbesaurus/status/937994790553227264
     vec3 oct_to_vec(vec2 e):
@@ -230,7 +231,7 @@ Decompression in the vertex shader (to convert back to cartesian coordinates) is
       v.xy += t * -sign(v.xy);
       return v;
 
-This approach can also be used to store the entire tangent space, using this technique to store the normal and tangent vector using vec2\<`SNORM8`\> but you will need to find a way to store the direction of the bitangent (needed for the common scenario where you have mirrored UV coordinates on a model). One way to implement this is to map a component of your tangent vector encoding to always be positive, then flip it's sign if you need to flip the bitangent direction and check for that in the vertex shader:  
+This approach can also be used to store the entire tangent space, using this technique to store the normal and tangent vector using vec2\<`SNORM8`\> but you will need to find a way to store the direction of the bitangent (needed for the common scenario where you have mirrored UV coordinates on a model). One way to implement this is to map a component of your tangent vector encoding to always be positive, then flip it's sign if you need to flip the bitangent direction and check for that in the vertex shader:
 
     const int BITS = 8
     const float bias = 1.0 / (2^(BITS - 1) - 1)
@@ -258,28 +259,29 @@ This approach can also be used to store the entire tangent space, using this tec
     vec3 tangent_real = oct_to_vec3(encode);
     float binormal_sign = sign(tangent_encode.y);
 
-| **Note:** Storing at this bit precision may raise some issues for highly specular materials. Keep that in mind and test to see what works best for your assets!
+> [!NOTE]
+> **Note:** Storing at this bit precision may raise some issues for highly specular materials. Keep that in mind and test to see what works best for your assets!
 
-|            |      Format       |   Size   |
-|------------|-------------------|----------|
+|   | Format | Size |
+|---|---|---|
 | **Before** | vec3\<`float32`\> | 12 bytes |
-| **After**  | vec2\<`SNORM8`\>  | 2 bytes  |
+| **After** | vec2\<`SNORM8`\> | 2 bytes |
 
 ### Vertex UV Coordinates
 
 UV Coordinates, used for texture mapping (among other things), are typically stored using 32 bit floats. Compressing them with 16 bit floats causes precision issues for textures larger than 1024x1024; floating-point precision between \[0.5, 1.0\] means that values will increment by larger than 1 pixel!
 
-The better approach is to use unsigned normalized integers (UNORM), specifically UNORM16; this provides uniform distribution across the entire texture coordinate range, supporting textures up to 65536x65536! This assumes texture coordinates are within the range \[0.0, 1.0\] per element, which may not be the case depending on the mesh (for example walls can use wrapping texture coordinates that go beyond 1.0) so keep that in mind when looking at this technique. The conversion function would look like this:  
+The better approach is to use unsigned normalized integers (UNORM), specifically UNORM16; this provides uniform distribution across the entire texture coordinate range, supporting textures up to 65536x65536! This assumes texture coordinates are within the range \[0.0, 1.0\] per element, which may not be the case depending on the mesh (for example walls can use wrapping texture coordinates that go beyond 1.0) so keep that in mind when looking at this technique. The conversion function would look like this:
 
     const int BITS = 16
 
     for each vertex_uv V in mesh:
       V *= clamp(2^BITS - 1, 0, 2^BITS - 1);  // float to integer value conversion
 
-|            |      Format       |  Size   |
-|------------|-------------------|---------|
+|   | Format | Size |
+|---|---|---|
 | **Before** | vec2\<`float32`\> | 8 bytes |
-| **After**  | vec2\<`UNORM16`\> | 4 bytes |
+| **After** | vec2\<`UNORM16`\> | 4 bytes |
 
 ### Vertex Compression Results
 
@@ -297,19 +299,22 @@ These vertex compression techniques led to a 66% reduction in vertex memory stor
 
 ![Android GPU Inspector view of uncompressed vertices](https://developer.android.com/static/images/games/vertex/vertex-unsplit-uncompressed.png "AGI with uncompressed vertices")
 
-**Figure 3:**Android GPU Inspector view of uncompressed vertices
+**Figure
+3:** Android GPU Inspector view of uncompressed vertices
 
 ![Android GPU Inspector view of compressed vertices](https://developer.android.com/static/images/games/vertex/vertex-unsplit-compressed.png "AGI with compressed vertices")
 
-**Figure 4:**Android GPU Inspector view of compressed vertices
+**Figure
+4:** Android GPU Inspector view of compressed vertices
 
 ## Vertex Stream Splitting
 
 Vertex Stream Splitting optimizes the organization of data in the vertex buffer. This is a cache performance optimization that makes a difference on tile-based GPUs typically found in Android Devices - in particular during the binning step of the rendering process.
 
-Tile-based GPUs create a shader that calculates the normalized device coordinates based on the provided vertex shader to do binning. It is executed first on every vertex in the scene, whether visible or not. Keeping vertex position data contiguous in memory is therefore a big plus. Other places this vertex stream layout can be beneficial is for shadow passes, as usually you only need position data for shadow calculations, as well as depth prepasses, which is a technique usually used for console/desktop rendering; this vertex stream layout can be a win for multiple classes of the rendering engine!
+Tile-based GPUs create a shader that calculates the normalized device coordinates based on the provided vertex shader to do binning. It is executed first on every vertex in the scene, whether visible or not. Keeping vertex position data contiguous in memory is therefore a big plus.
+Other places this vertex stream layout can be beneficial is for shadow passes, as usually you only need position data for shadow calculations, as well as depth prepasses, which is a technique usually used for console/desktop rendering; this vertex stream layout can be a win for multiple classes of the rendering engine!
 
-Stream Splitting involves setting up the vertex buffer with a contiguous section of vertex position data and another section containing interleaved vertex attributes. Most applications usually set up their buffers fully interleaving all attributes. This visual explains the difference:  
+Stream Splitting involves setting up the vertex buffer with a contiguous section of vertex position data and another section containing interleaved vertex attributes. Most applications usually set up their buffers fully interleaving all attributes. This visual explains the difference:
 
     Before:
     |Position1/Normal1/Tangent1/UV1/Position2/Normal2/Tangent2/UV2......|
@@ -317,7 +322,8 @@ Stream Splitting involves setting up the vertex buffer with a contiguous section
     After:
     |Position1/Position2...|Normal1/Tangent1/UV1/Normal2/Tangent2/UV2...|
 
-Looking at how the GPU fetches vertex data helps us understand the benefits of stream splitting. Assuming for the sake of argument:
+Looking at how the GPU fetches vertex data helps us understand the benefits of
+stream splitting. Assuming for the sake of argument:
 
 - 32 byte cache lines (a pretty common size)
 - Vertex format consisting of:
@@ -344,11 +350,13 @@ Now, if we combine the vertex stream splitting with vertex compression, we will
 
 ![Android GPU Inspector view of unsplit vertex streams](https://developer.android.com/static/images/games/vertex/vertex-unsplit-uncompressed.png "AGI with unsplit vertex streams")
 
-**Figure 5:**Android GPU Inspector view of unsplit vertex streams
+**Figure
+5:** Android GPU Inspector view of unsplit vertex streams
 
 ![Android GPU Inspector view of split vertex streams](https://developer.android.com/static/images/games/vertex/vertex-split-uncompressed.png "AGI with split vertex streams")
 
-**Figure 6:**Android GPU Inspector view of split vertex streams
+**Figure
+6:** Android GPU Inspector view of split vertex streams
 
 ## Compound Results
 
@@ -364,11 +372,13 @@ Now, if we combine the vertex stream splitting with vertex compression, we will
 
 ![Android GPU Inspector view of unsplit vertex streams](https://developer.android.com/static/images/games/vertex/vertex-unsplit-uncompressed.png "AGI with unsplit uncompressed vertex streams")
 
-**Figure 7:**Android GPU Inspector view of unsplit, uncompressed vertex streams
+**Figure
+7:** Android GPU Inspector view of unsplit, uncompressed vertex streams
 
 ![Android GPU Inspector view of unsplit vertex streams](https://developer.android.com/static/images/games/vertex/vertex-split-compressed.png "AGI with split compressed vertex streams")
 
-**Figure 8:**Android GPU Inspector view of split, compressed vertex streams
+**Figure
+8:** Android GPU Inspector view of split, compressed vertex streams
 
 ## Additional Considerations
 
